summary(promotion_aov)
dataQ1 = matrix(NA, nrow=2, ncol=10)
dataQ1[1,] = c(100, 95, 125, 105, 100, 90, 135, 120, 85, 101)
dataQ1[2,] = c(90, 110, 85, 90, 95, 110, 115, 110, 105, 120)
rownames(dataQ1) = c("Goose Bar", "Cheap Dinner")
dataQ1
n1 <- 10
n2 <- 10
mu_hat <- mean(dataQ1)
mu_hat
t1 <- mean(dataQ1[1,]) - mu_hat
t1
t2 <- mean(dataQ1[2,]) - mu_hat
t2
var_hat <- ((n1 - 1)*var(dataQ1[1,]) + (n2 - 1)*var(dataQ1[2,]))/(n1 + n2 - 2)
var_hat
c <- qt(0.975, n1 + n2 - 2)
# confidence interval:
diff_lower <- t1 - t2 - c*sqrt(var_hat)*sqrt(1/n1 + 1/n2)
diff_upper <- t1 - t2 + c*sqrt(var_hat)*sqrt(1/n1 + 1/n2)
print(paste('Lower Bound:',round(diff_lower,3),'Upper Bound:',round(diff_upper,3)))
dataQ2 = matrix(NA, nrow=1, ncol=10)
dataQ2[1,] = c(250, 175, 140, 200, 195, 165, 145, 180, 210, 180)
rownames(dataQ2) = c("Carbwich")
dataQ2
three_treatments <- data.frame(t(dataQ1))
three_treatments$Carbwich <- c(250, 175, 140, 200, 195, 165, 145, 180, 210, 180)
boxplot(three_treatments, xlab = 'Promotion Type', ylab = 'Profit')
anova_mat <- matrix(nrow=30,ncol = 2)
anova_mat[,1] <- c(dataQ1[1,],dataQ1[2,],three_treatments$Carbwich)
anova_mat[,2] <- c(rep(1,10),rep(2,10),rep(3,10))
anova_df <- as.data.frame(anova_mat)
colnames(anova_df) <- c("profit","promotion")
anova_df$promotion <- as.factor(anova_df$promotion)
attach(anova_df)
promotion_aov <- aov(profit ~ promotion, data = anova_df)
summary(promotion_aov)
anova_mat <- matrix(nrow=30,ncol = 2)
anova_mat[,1] <- c(dataQ1[1,],dataQ1[2,],three_treatments$Carbwich)
anova_mat[,2] <- c(rep(1,10),rep(2,10),rep(3,10))
anova_df <- as.data.frame(anova_mat)
colnames(anova_df) <- c("profit","promotion")
anova_df$promotion <- as.factor(anova_df$promotion)
promotion_aov <- aov(profit ~ promotion, data = anova_df)
summary(promotion_aov)
40/6
5/6.666667
1 - pf(0.75, 2, 6)
results_prob
setwd("~/Desktop/DataSci/data_572/assignments")
library(MLmetrics)
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
car_data <- read.csv("car93.csv")
head(car_data)
car_pca <- prcomp(car_data[,-c(1,2,3)], scale.=TRUE)
summary(car_pca)
biplot(car_pca)
plot(car_pca, type="lines")
car_pca$rotation[,1:2]
car_data$response <- ifelse(car_data$Type == 'Small', 1, 0)
as.factor(car_data$response)
log_reg_data <- data.frame(car_pca$x[,1:2])
log_reg_data$response <- as.factor(car_data$response)
head(log_reg_data)
library(MLmetrics)
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
mean(log_loss)
results_prob
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
#mean(log_loss)
(sum(-log(results_prob[log_reg_data$response==results_binary])) + sum(-log(1-results_prob[log_reg_data$response!=results_binary])))/82
library(MLmetrics)
results_prob <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
}
#CV LogLoss
log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
mean(log_loss)
library(MLmetrics)
results_prob <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
}
#CV LogLoss
log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
mean(log_loss)
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
#mean(log_loss)
(sum(-log(results_prob[log_reg_data$response==results_binary])) + sum(-log(1-results_prob[log_reg_data$response!=results_binary])))/82
results_prob
results_binary
results_prob[log_reg_data$response==results_binary]
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
#mean(log_loss)
(sum(-log(results_prob[log_reg_data$response==1)) + sum(-log(1-results_prob[log_reg_data$response!=1])))/82
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#log_loss[i] <- LogLoss(logistic_reg$fitted.values,as.numeric(train$response)-1)
#mean(log_loss)
(sum(-log(results_prob[log_reg_data$response==1])) + sum(-log(1-results_prob[log_reg_data$response!=1])))/82
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#(sum(-log(results_prob[log_reg_data$response==1])) + #sum(-log(1-results_prob[log_reg_data$response!=1])))/82
LogLoss(results_binary, as.numeric(log_reg_data$response)-1)
?LogLoss
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#(sum(-log(results_prob[log_reg_data$response==1])) + #sum(-log(1-results_prob[log_reg_data$response!=1])))/82
LogLoss(results_prob, as.numeric(log_reg_data$response)-1)
library(MLmetrics)
results_prob <- NULL
results_binary <- NULL
log_loss <- NULL
for (i in seq(length(car_data$response))){
train <- log_reg_data[-i,]
test <- log_reg_data[i,]
logistic_reg <- glm(response ~., data = train, family = binomial)
results_prob[i] <- predict(logistic_reg,subset(test,select=c(1,2)),type='response')
results_binary[i] <- ifelse(results_prob[i] > 0.5, 1, 0)
}
#CV LogLoss
#(sum(-log(results_prob[log_reg_data$response==1])) + #sum(-log(1-results_prob[log_reg_data$response!=1])))/82
LogLoss(results_prob, as.numeric(log_reg_data$response)-1)
?MultiLogLoss
lin_da$posterior[,2]
library(dplyr)
log_reg_data$response <- car_data$Type
log_reg_data <- log_reg_data %>% mutate(response=ifelse(response=="Small",1,ifelse(response=="Compact",2,ifelse(response=="Large",3,ifelse(response=="Midsize",4,ifelse(response=='Sporty',5,NA))))))
log_reg_data$response <- as.factor(log_reg_data$response)
lin_da <- lda(log_reg_data$response~., data=log_reg_data, CV=T)
table(log_reg_data$response, lin_da$class)
lin_da$posterior[,2]
#LOOCV LDA Log Loss on 5 car types:
#Multiclass
MultiLogLoss(lin_da$posterior[,2], as.numeric(log_reg_data$response)-1)
log_reg_data$response
data(iris)
svm.model <- e1071::svm(Species~., data = iris, probability = TRUE)
pred <- predict(svm.model, iris, probability = TRUE)
library(datasets)
#LOOCV LDA Log Loss on 5 car types:
#Multiclass
MultiLogLoss(lin_da$posterior[,2], as.numeric(log_reg_data$response))
library(dplyr)
log_reg_data$response <- car_data$Type
log_reg_data <- log_reg_data %>% mutate(response=ifelse(response=="Small",1,ifelse(response=="Compact",2,ifelse(response=="Large",3,ifelse(response=="Midsize",4,ifelse(response=='Sporty',5,NA))))))
log_reg_data$response <- as.factor(log_reg_data$response)
lin_da <- lda(log_reg_data$response~., data=log_reg_data, CV=T)
table(log_reg_data$response, lin_da$class)
lin_da
#LOOCV LDA Log Loss on 5 car types:
#Multiclass
MultiLogLoss(lin_da$posterior, as.numeric(log_reg_data$response)-1)
library(nnet)
set.seed(4521, sample.kind = "Rounding")
fish_data <- read.csv('fish_toxicity.csv', sep = ';')
sfish <- apply(fish_data, 2, function(v) (v-min(v))/(max(v)-min(v)))
nnfish <- nnet(factor(sfish[,7])~., data=sfish, size=5)
sfish
library(nnet)
set.seed(4521, sample.kind = "Rounding")
fish_data <- read.csv('fish_toxicity.csv', sep = ';')
sfish <- apply(fish_data, 2, function(v) (v-min(v))/(max(v)-min(v)))
nnfish <- nnet(sfish[,7]~., data=sfish, size=5)
library(nnet)
set.seed(4521, sample.kind = "Rounding")
fish_data <- read.csv('fish_toxicity.csv', sep = ';', header = FALSE)
sfish <- apply(fish_data, 2, function(v) (v-min(v))/(max(v)-min(v)))
nnfish <- nnet(sfish[,7]~., data=sfish, size=5)
library(nnet)
set.seed(4521, sample.kind = "Rounding")
fish_data <- read.csv('fish_toxicity.csv', sep = ';', header = FALSE)
sfish <- apply(fish_data, 2, function(v) (v-min(v))/(max(v)-min(v)))
sfish <- as.data.frame(sfish)
nnfish <- nnet(sfish[,7]~., data=sfish, size=5)
library(nnet)
set.seed(4521, sample.kind = "Rounding")
fish_data <- read.csv('fish_toxicity.csv', sep = ';', header = FALSE)
sfish <- apply(fish_data, 2, function(v) (v-min(v))/(max(v)-min(v)))
sfish <- as.data.frame(sfish)
nnfish <- nnet(V7~., data=sfish, size=5)
sum(v7-predict(nnfish,data = sfish))/length((sfish$V7))
sum(V7-predict(nnfish,data = sfish))/length((sfish$V7))
sum(sfish$V7-predict(nnfish,data = sfish))/length((sfish$V7))
sum((sfish$V7-predict(nnfish,data = sfish))^2)/length((sfish$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((sfish$V7-predict(nnfish_tr,data = test))^2)/length((sfish$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((sfish$V7-predict(nnfish_tr,data = test))^2)/length((sfish_tr$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((sfish$V7-predict(nnfish_tr,data = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((train$V7-predict(nnfish_tr,data = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((test$V7-predict(nnfish_tr,data = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((test$V7-predict(nnfish_tr,newdata = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
sum((test$V7-predict(nnfish_tr, newdata = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
nnfish_tr <- nnet(V7~., data=train, size=5)
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
nnfish_tr_orig <- nnet(V7~., data=train, size=5)
sum((test$V7-predict(nnfish_tr_orig, newdata = test))^2)/length((train$V7))
fish_lm <- lm(V7 ~., data = train)
sum((test$V7-predict(fish_lm, newdata = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
fish_lm <- lm(V7 ~., data = train)
sum((test$V7-predict(fish_lm, newdata = test))^2)/length((train$V7))
fish_lm <- lm(V7 ~., data = train)
sum((test$V7-predict(fish_lm, newdata = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
nnfish_tr_orig <- nnet(V7~., data=train, size=5)
fish_lm <- lm(V7 ~., data = train)
sum((test$V7-predict(fish_lm, newdata = test))^2)/length((train$V7))
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(sfish), 454)
train <- sfish[ind,]
test <- sfish[-ind,]
fish_lm <- lm(V7 ~., data = train)
sum((test$V7-predict(fish_lm, newdata = test))^2)/length((train$V7))
#for non-normalized
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7))
}
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7))
}
#for non-normalized
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7))
}
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7))
}
#for non-normalized
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#for non-normalized
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
set.seed(217, sample.kind="Rounding")
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#for non-normalized
set.seed(217)
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
set.seed(217)
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#for non-normalized
set.seed(217)
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#for non-normalized
set.seed(217)
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
set.seed(217)
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#switching to linear activation function
for(i in 1:10){
set.seed(217)
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#for non-normalized
set.seed(217)
ind <- sample(1:nrow(fish_data), 454)
train <- fish_data[ind,]
test <- fish_data[-ind,]
#trying different number of hidden layer variables for logistic activation fxn
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, trace = FALSE)
print(paste("Number of hidden layer variables using logistic activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
#switching to linear activation function
for(i in 1:10){
nnfishtr <- nnet(V7~., data=train, size=i, linout = TRUE, trace = FALSE)
print(paste("Number of hidden layer variables using linear activ. fxn:", i))
print(sum((test$V7-predict(nnfishtr, newdata = test))^2)/length((train$V7)))
}
setwd("~/Desktop/DataSci/data_534")
setwd("~/Desktop/DataSci/data_534")
setwd("~/Desktop/DataSci/data_534/driveBC")
